%!TEX root =  main.tex
\subsection{One-way ANOVA}

Consider again our example from earlier, where a researcher has, for a set of individuals, both blood pressure measurements and the mutation status of a particular gene.  This is a classic setting for a one-way analysis of variance (ANOVA) test.

Index each individual person or observation in a database $\x$ with $i \in \{1, \ldots, N\}$. Each $i$ is associated with a group or category $c_i$ (e.g., mutation status) and a numerical value $y_i \in \mathbb{R}$ (e.g., blood pressure).  We use $\bar{y}$ to represent the mean of all $N$ numerical values. Index each group with $j \in \{1, \ldots, k\}$. Each $j$ is associated with $C_j = \{i \mid c_i=j\}$, the set of indices of observations in group $j$. Denote the size of the set $n_j$ and the mean of the values in that set $\bar{y}_j$.  (Note that this means $\bar{y}_{c_i}$ is the mean of numerical values in the same group as observation $i$.)

The null hypothesis in a one-way ANOVA is that the $y_i$ follow identical normal distributions regardless of their group. This motivates the test statistic used in an ANOVA test, the $F$-statistic, which measures the ratio of the variation between group means (weighted by the size of the groups) and the variation of individuals within each group. If all groups had equal means, the variation between group means would be proportional to the variation between individual observations.\footnote{Our approach relies upon simulating normally distributed data in correspondence with the traditional normality assumption. The one-way ANOVA test is known to be robust to deviations from normality~\cite{schmider2010}, so our approach should be applicable even in settings where the normality assumption is suspect. Readers interested in more about ANOVA generally are referred to \cite{cox1974theoretical}.}

\begin{definition}[$F$-Statistic] \label{def:fstat}
Given a database \x with $k$ groups and \dbsize total entries, the $F$-statistic is the ratio of two values, traditionally called $\ssa(\x)$ and $\sse(\x)$.  The Sum of Squared errors of All category means ($\ssa$) is a measure of variance between group means, weighted by group size:
\begin{equation*}
\ssa(\x) = \sum_{j=1}^{\k} n_j (\bar{y}_j - \bar{y})^2.
\end{equation*}
The Sum of Squared Errors of all observations ($\sse$) is a measure of variance within groups:
\begin{equation*}
\sse(\x) = \sum_{i=1}^{\dbsize}  (y_{i}-\bar{y}_{c_i})^2.
\end{equation*}
The $F$-statistic is the ratio of \ssa and \sse, each divided by their respective degrees of freedom.  These adjusted values are called  the Mean Sum of All category errors (\msa) and Mean of Sum of Squared Errors (\mse).
We can now finish defining the $F$-statistic.
\begin{equation*}
F(\x)  = \frac{\ssa(\x)/(\k - 1)}{\sse(\x)/(\dbsize - \k)} = \frac{\msa(\x)}{\mse(\x)}.
\end{equation*}
\end{definition}

Under the null hypothesis that the $y_i$ follow identical normal distributions regardless of their group, the reference distribution of the $F$-statistic is known exactly. This comes from recognizing that $\ssa(\x)$ is drawn from $\sigma^2\chi_{\k-1}^2$, the chi-squared distribution with $\k-1$ degrees of freedom scaled by within-group variance, and $\sse(\x)$ is drawn from $\sigma^2 \chi^2_{\dbsize - \k}$.  The ratio of these values, therefore, has a reference distribution that is scale-free (not dependent on $\sigma$) and can be calculated knowing only $N$ and $k$.

% {\color{violet}
% \noindent (Trying something out -- Anna) Let the groups or categories be denoted as a set $C$, where $|C|=k$.  Each observation $i$ is associated with a category $c_i \in C$ and a value $y_i \in \mathbb{R}$.  Let $\bar{y}$ be the mean of all values.  For each category $c \in C$, let $n_c$ be the number of observations in that category (that is, $|\{i \mid c_i = c\}|$) and $\bar{y}_c$ be the mean value of that set.  Then,
% $$\ssa = \sum_{c \in C} n_c (\bar{y}_c - \bar{y})^2$$
% \noindent and
% $$\sse = \sum_{i=1}^{\dbsize}  (y_{i}-\bar{y}_{c_i})^2$$
% \noindent or (to avoid double-subscript, but adds a double sum):
% $$\sse = \sum_{c \in C} \sum_{i: c_i = c}  (y_{i}-\bar{y}_{c})^2$$
% \noindent Changes:  Categories are no longer indexed, meaning that only observations have indices.  Having both $i$ and $j$ make it seem like they both should refer to the same type of variable. I don't think we need the indices for categories later on (I may be mistaken).\\
% 
% }
